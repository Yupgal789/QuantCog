{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 11: Model Toolbox\n",
    "\n",
    "## Intro to Quantified Cognition\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/compmem/QuantCog/blob/master/notebooks/11_Model_Toolbox.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lesson plan\n",
    "\n",
    "- Review some best practices\n",
    "- Example of paramter recovery\n",
    "- Discuss Modeler's Toolbox\n",
    "- Example of Temporal Distinctiveness Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "- Show model fit\n",
    "- Assess parameter recovery\n",
    "- Demonstrate selective influence\n",
    "- Quantify uncertainty in parameter estimates\n",
    "- Engage in model selection\n",
    "\n",
    "(See great introduction by Heathcote et al., 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameter Recovery\n",
    "\n",
    "- Use a model to generate data with known parameters\n",
    "- Perform model fits to recover those parameters\n",
    "- Poor parameter recovery suggests difficulty in model interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selective Influence\n",
    "\n",
    "- One option is demonstration of ecological validity \n",
    "  - (e.g., success in a real-world application)\n",
    "- Barring that, we can perform experimental manipulations to isolate individual processes in the model\n",
    "  - Speed-accuracy trade-off\n",
    "  - Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *ONLY* if on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install RunDEMC\n",
    "!pip install git+https://github.com/compmem/RunDEMC.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the data\n",
    "!wget https://raw.githubusercontent.com/compmem/QuantCog/master/notebooks/decision_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the wfpt model\n",
    "!wget https://raw.githubusercontent.com/compmem/QuantCog/master/notebooks/wfpt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "from scipy import stats\n",
    "\n",
    "from RunDEMC.density import kdensity\n",
    "from RunDEMC import Model, Param, dists, calc_bpic, joint_plot\n",
    "\n",
    "from wfpt import wfpt_like, wfpt_gen\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "try:\n",
    "    import scoop\n",
    "    from scoop import futures\n",
    "except ImportError:\n",
    "    print(\"Error loading scoop, reverting to joblib.\")\n",
    "    scoop = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "dat = pd.read_csv('decision_data.csv', index_col=0)\n",
    "dat = dat[dat.cond != 'Neutral']\n",
    "dat['rt_acc'] = dat['rt']\n",
    "dat.loc[dat.correct==0,'rt_acc'] = -dat['rt']\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up the sim\n",
    "nsims = 5000\n",
    "cond='Accuracy'\n",
    "\n",
    "# normed histogram\n",
    "def dhist(dat, nvals, alpha=.3, color='b'):\n",
    "    p,b = np.histogram(dat,bins='auto',density=True)\n",
    "    w = b[1]-b[0]\n",
    "    p *= float(len(dat))/nvals\n",
    "    return plt.bar(b[1:]-w,p,width=w,alpha=.3,color=color)\n",
    "\n",
    "# normed pdf\n",
    "xvals = np.linspace(0.0,2.0,1000)\n",
    "choices = np.concatenate([np.ones(len(xvals))*2, np.ones(len(xvals))*1])\n",
    "rts = np.concatenate([xvals, xvals])\n",
    "\n",
    "# put it all together\n",
    "def run_wfpt(cond, v_mean, a, w_mode, w_std=0.0,\n",
    "             v_std=0.0, t0=0.0, nsamp=5000, err=.0001):\n",
    "\n",
    "    ndat = (dat['cond']==cond).sum()\n",
    "    # plot the hist of the data, followed by the model PDF line\n",
    "    dhist(np.array(dat[(dat['cond']==cond)&(dat['correct']==1)]['rt']), ndat, color='b')\n",
    "    likes = wfpt_like(choices, rts, v_mean, a, w_mode, w_std=w_std,\n",
    "                      v_std=v_std, t0=0, nsamp=nsamp, err=err)\n",
    "    plt.plot(xvals+t0, likes[choices==2], color='b', lw=2.)\n",
    "    \n",
    "    dhist(np.array(dat[(dat['cond']==cond)&(dat['correct']==0)]['rt']), ndat, color='r')\n",
    "    plt.plot(xvals+t0, likes[choices==1], color='r', lw=2.)\n",
    "    #ylim(0,5.0)\n",
    "    plt.xlim(0,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up new figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# try different params!\n",
    "cond='Accuracy'\n",
    "\n",
    "v_mean = 3.0\n",
    "v_std = 2.0\n",
    "a = 1.5\n",
    "w_mode = 0.4\n",
    "w_std = 0.1\n",
    "t0 = .29\n",
    "\n",
    "# call the function\n",
    "run_wfpt(cond, v_mean, a, w_mode, w_std=w_std,\n",
    "         v_std=v_std, t0=t0, nsamp=1000, err=.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using computers to test hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the beh data of interest\n",
    "choices_A = np.array(dat[(dat['cond']=='Accuracy')]['correct']+1)\n",
    "rts_A = np.array(dat[(dat['cond']=='Accuracy')]['rt'])\n",
    "choices_S = np.array(dat[(dat['cond']=='Speed')]['correct']+1)\n",
    "rts_S = np.array(dat[(dat['cond']=='Speed')]['rt'])\n",
    "print(len(choices_A), len(choices_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the required def for RunDEMC\n",
    "def eval_fun(pop, *args):\n",
    "    pnames = args[0]\n",
    "\n",
    "    if scoop and scoop.IS_RUNNING:\n",
    "        likes = list(futures.map(eval_mod, [indiv for indiv in pop],\n",
    "                                 [pnames]*len(pop)))\n",
    "    else:\n",
    "        # use joblib\n",
    "        likes = Parallel(n_jobs=-1)(delayed(eval_mod)(indiv, pnames)\n",
    "                                    for indiv in pop)\n",
    "\n",
    "    return np.array(likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test change in threshold\n",
    "\n",
    "# set up the params\n",
    "params = [Param(name='v_A', prior=dists.normal(0., 2.)),\n",
    "          #Param(name='v_S', prior=dists.normal(0., 2.)),\n",
    "          Param(name='v_std', prior=dists.halfcauchy(2.0)),\n",
    "          Param(name='w', prior=dists.normal(0, 1.4), transform=dists.invlogit),\n",
    "          Param(name='w_std', prior=dists.halfcauchy(0.5)),\n",
    "          Param(name='a_A', prior=dists.trunc_normal(2.0, 2.0, 0., 5.0)),\n",
    "          #Param(name='a_S', prior=dists.trunc_normal(2.0, 2.0, 0., 5.0)),\n",
    "          Param(name='t0', prior=dists.trunc_normal(.2, 1.0, 0., 1.0))]\n",
    "param_names = [p.name for p in params]\n",
    "\n",
    "# define the likelihood function\n",
    "def eval_mod(params, param_names):\n",
    "    log_like = 0.0\n",
    "    p = {param_names[j]: params[j] for j in range(len(params))}\n",
    "    \n",
    "    # first Accuracy\n",
    "    likes_A = wfpt_like(choices_A, rts_A, \n",
    "                        v_mean=p['v_A'], v_std=p['v_std'], a=p['a_A'], \n",
    "                        w_mode=p['w'], t0=p['t0'], w_std=p['w_std'], \n",
    "                        nsamp=1000)\n",
    "    log_like += np.log(likes_A).sum()\n",
    "\n",
    "    # then Speed\n",
    "    #likes_S = wfpt_like(choices_S, rts_S, \n",
    "    #                    v_mean=p['v_S'], v_std=p['v_std'], a=p['a_S'], \n",
    "    #                    w_mode=p['w'], t0=p['t0'], w_std=p['w_std'], \n",
    "    #                    nsamp=1000)\n",
    "    #log_like += np.log(likes_S).sum()\n",
    "\n",
    "    return log_like\n",
    "        \n",
    "# make the model\n",
    "m = Model('all', params=params,\n",
    "          like_fun=eval_fun,\n",
    "          like_args=(param_names,),\n",
    "          #purify_every=5,\n",
    "          verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# do some burnin\n",
    "times = m.sample(75, burnin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(m.weights[30:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m.particles[10:, :, 3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Best fitting params:\")\n",
    "burnin=5\n",
    "best_ind = m.weights[burnin:].argmax()\n",
    "print(\"Weight:\", m.weights[burnin:].ravel()[best_ind])\n",
    "indiv = [m.particles[burnin:,:,i].ravel()[best_ind] \n",
    "         for i in range(m.particles.shape[-1])]\n",
    "pp = {}\n",
    "for p,v in zip(m.param_names,indiv):\n",
    "    pp[p] = v\n",
    "    print('\"%s\": %f,'%(p,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBA fit to Accuracy condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the beh data of interest\n",
    "dat_A_1 = np.array(dat[(dat['cond']=='Accuracy')&(dat['correct']==0)]['rt'])\n",
    "dat_A_2 = np.array(dat[(dat['cond']=='Accuracy')&(dat['correct']==1)]['rt'])\n",
    "num_A = float((dat['cond']=='Accuracy').sum())\n",
    "prop_A_1 = len(dat_A_1)/num_A\n",
    "prop_A_2 = len(dat_A_2)/num_A\n",
    "dat_S_1 = np.array(dat[(dat['cond']=='Speed')&(dat['correct']==0)]['rt'])\n",
    "dat_S_2 = np.array(dat[(dat['cond']=='Speed')&(dat['correct']==1)]['rt'])\n",
    "num_S = float((dat['cond']=='Speed').sum())\n",
    "prop_S_1 = len(dat_S_1)/num_S\n",
    "prop_S_2 = len(dat_S_2)/num_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lba_sim(I=(1.0,1.5), A=.1, S=1.0, b=1.0, t0=0.0, \n",
    "            num_sims=1000, max_time=2., I_scales_S=False, **kwargs):\n",
    "    # set drift rate from inputs\n",
    "    dr = np.float64(I)\n",
    "    \n",
    "    # set the number of choices\n",
    "    nc = len(dr)\n",
    "    \n",
    "    # pick starting points\n",
    "    k = np.random.uniform(0., A, (num_sims, nc))\n",
    "    \n",
    "    # pick drifts\n",
    "    if I_scales_S:\n",
    "        # calc S from drift rates\n",
    "        S = np.sqrt((dr**2).sum())*S\n",
    "        \n",
    "    # must make sure at least one d is greater than zero for each sim\n",
    "    d = np.random.normal(dr, S, (num_sims, nc))\n",
    "    \n",
    "    # see where there are none above zero\n",
    "    #ind = np.all(d<=0.0,axis=1)\n",
    "    #while np.any(ind):\n",
    "    #    d[ind,:] = np.random.normal(dr,S,(ind.sum(),nc))\n",
    "    #    ind = np.all(d<=0.0,axis=1)\n",
    "\n",
    "    # clip it to avoid divide by zeros\n",
    "    d[d<=0.0] = np.finfo(dr.dtype).eps\n",
    "\n",
    "    # calc the times for each\n",
    "    t = (b-k)/d\n",
    "\n",
    "    # see the earliest for each resp\n",
    "    inds = t.argmin(1)\n",
    "    times = t.take(inds+np.arange(t.shape[0])*t.shape[1])\n",
    "\n",
    "    # process into choices\n",
    "    times += t0\n",
    "    \n",
    "    # get valid responses\n",
    "    resp_ind = times < (max_time)\n",
    "    resp = inds+1\n",
    "    resp[~resp_ind] = 0\n",
    "    \n",
    "    # return as data frame\n",
    "    return pd.DataFrame.from_dict({'response':resp, 'rt':times})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** INCOMPLETE ***\n",
    "\n",
    "# set up the params\n",
    "params = [Param(name='d1', prior=dists.trunc_normal(1., 2., 0., 10.)),\n",
    "          Param(name='d2', prior=dists.trunc_normal(1., 2., 0., 10.)),\n",
    "          Param(name='A', prior=dists.trunc_normal(.5, 2.0, 0., 2.0)),\n",
    "          Param(name='b_A', prior=dists.trunc_normal(2.0, 2.0, 0., 5.0)),\n",
    "          Param(name='b_S', prior=dists.trunc_normal(2.0, 2.0, 0., 5.0)),\n",
    "          Param(name='t0', prior=dists.trunc_normal(.2, 1.0, 0., 1.0))]\n",
    "param_names = [p.name for p in params]\n",
    "\n",
    "# define the likelihood function\n",
    "nsims = 10000\n",
    "max_time = 2.0\n",
    "extrema = (0, max_time)\n",
    "S = 1.0\n",
    "def eval_mod(params, param_names):\n",
    "    log_like = 0.0\n",
    "    p = {param_names[j]: params[j] for j in range(len(params))}\n",
    "    \n",
    "\n",
    "    # first check for simple issues\n",
    "    if (p['A'] > p['b_A']) or (p['A'] > p['b_S']) or np.any(params<0):\n",
    "        # A can't be bigger than b\n",
    "        likes[i] = -np.inf\n",
    "        continue\n",
    "\n",
    "    # first Accuracy\n",
    "    res = lba_sim(I=(p['d1'], p['d2']), A=p['A'], S=S, b=p['b_A'], \n",
    "                  num_sims=nsims, max_time=max_time, t0=p['t0'])\n",
    "\n",
    "    # process first response\n",
    "    rts = res.loc[res['response'] == 1, 'rt']\n",
    "    if len(rts)>2:\n",
    "        pp,xx = kdensity(rts, extrema=extrema, xx=dat_A_1)\n",
    "        pp *= float(len(rts))/nsims\n",
    "        likes[i] += np.log(pp).sum()\n",
    "    else:\n",
    "        likes[i] = -np.inf\n",
    "        continue\n",
    "\n",
    "    # process second response\n",
    "    rts = res.loc[res['response'] == 2, 'rt']\n",
    "    if len(rts)>2:\n",
    "        pp,xx = kdensity(rts, extrema=extrema, xx=dat_A_2)\n",
    "        pp *= float(len(rts))/nsims\n",
    "        likes[i] += np.log(pp).sum()\n",
    "    else:\n",
    "        likes[i] = -np.inf\n",
    "        continue\n",
    "\n",
    "    # then Speed\n",
    "    res = lba_sim(I=(p['d1'], p['d2']), A=p['A'], S=S, b=p['b_S'], \n",
    "                  num_sims=nsims, max_time=max_time, t0=p['t0'])\n",
    "\n",
    "    # process first response\n",
    "    rts = res.loc[res['response'] == 1, 'rt']\n",
    "    if len(rts)>2:\n",
    "        pp,xx = kdensity(rts, extrema=extrema, xx=dat_S_1)\n",
    "        pp *= float(len(rts))/nsims\n",
    "        likes[i] += np.log(pp).sum()\n",
    "    else:\n",
    "        likes[i] = -np.inf\n",
    "        continue\n",
    "\n",
    "    # process second response\n",
    "    rts = res.loc[res['response'] == 2, 'rt']\n",
    "    if len(rts)>2:\n",
    "        pp,xx = kdensity(rts, extrema=extrema, xx=dat_S_2)\n",
    "        pp *= float(len(rts))/nsims\n",
    "        likes[i] += np.log(pp).sum()\n",
    "    else:\n",
    "        likes[i] = -np.inf\n",
    "        continue\n",
    "\n",
    "    return likes\n",
    "        \n",
    "# make the model\n",
    "m_t = Model('thresh', params=params,\n",
    "            like_fun=like_fun,\n",
    "            like_args=(dat,),\n",
    "            purify_every=5,\n",
    "            verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Toolkit\n",
    "\n",
    "- What are the coding equivalents for common cognitive processes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items/Stimuli\n",
    "\n",
    "- A cognitive model must *represent* the stimuli in your experiment. \n",
    "- This can be as simple as a vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orthogonal items in a list-learning experiment\n",
    "nitems = 10\n",
    "items = np.eye(nitems)\n",
    "\n",
    "plt.imshow(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping items\n",
    "\n",
    "- Sometimes it's necessary for items to overlap (i.e., perceptually or semantically)\n",
    "- Here you can simply add columns to your items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlapping items in a list-learning experiment\n",
    "nitems = 10\n",
    "ncolors = 2\n",
    "nfeatures = nitems + ncolors\n",
    "items = np.eye(nfeatures)\n",
    "items = items[:nitems]\n",
    "\n",
    "# add in color features\n",
    "items[1::2, -1] = 1\n",
    "items[::2, -2] = 1\n",
    "\n",
    "plt.imshow(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working memory\n",
    "\n",
    "- We can keep stimuli active, even when not just-presented\n",
    "- Some options are:\n",
    "  - buffers (e.g., SAM, Atkinson & Shiffrin)\n",
    "  - exponential decay (e.g., TCM, Howard & Kahana)\n",
    "  - time cells (e.g., SITH/TILT, Howard & Shankar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present a list of items and store in working memory (context)\n",
    "c = np.zeros(nfeatures)\n",
    "c_save = []\n",
    "rho = .5\n",
    "for i in items:\n",
    "    c = rho*c + (1-rho)*i\n",
    "    c_save.append(c)\n",
    "plt.imshow(c_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associations\n",
    "\n",
    "- In order to have a longer-term memory, we must form associations\n",
    "- If items (and other information, such as working memory) is a vector, you can store and update associations in a matrix\n",
    "- There are *many* potential associative memory rules:\n",
    "  - Hebbian (simple outer product)\n",
    "  - Prediction-error (e.g., Rescorla--Wagner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form an outer product between an item and context\n",
    "M = np.zeros((nfeatures, nfeatures))\n",
    "for i in range(len(items)):\n",
    "    M = M + np.outer(items[i], c_save[i])\n",
    "plt.imshow(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Memory\n",
    "\n",
    "- Once we have information stored in a matrix, you can pull it out with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.dot(M, c_save[4])\n",
    "plt.plot(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n",
    "\n",
    "- If we have a strength value, we still need to generate a behavior\n",
    "- Here we can employ many types of decision rules\n",
    "- If we don't care about reaction-times, we can use a softmax rule:\n",
    "\n",
    "$$\\frac{e^{\\tau s_i}}{\\sum_{j} e^{\\tau s_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Distinctiveness Example\n",
    "\n",
    "In Siefke et al. (2019, *Memory & Cognition*) we wanted to test what it meant for an experience to be disctinctive:\n",
    "\n",
    "https://link.springer.com/content/pdf/10.3758%2Fs13421-019-00925-5.pdf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
