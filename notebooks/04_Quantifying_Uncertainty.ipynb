{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 4: Quantifying Uncertainty\n",
    "\n",
    "## Intro to Quantified Cognition\n",
    "\n",
    "By: Per B. Sederberg, PhD\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/compmem/QuantCog/blob/2020_Spring/notebooks/04_Quantifying_Uncertainty.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lesson plan\n",
    "\n",
    "- Review of model fitting\n",
    "- Bayes Factor for model comparison\n",
    "- Introduce Bayesian approaches\n",
    "- How to solve it... MCMC!\n",
    "- Metropolis-Hastings\n",
    "- Code MCMC\n",
    "- Validate MCMC\n",
    "- Bayesian t-test example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximum Likelihood / Bayes Factor approach\n",
    "\n",
    "Last class we learned that we can calculate parameters that maximize the likelihood of observing the data given the model and those parameters:\n",
    "\n",
    "$$\\hat{L} = P(D \\mid \\hat{\\theta}, M)$$\n",
    "\n",
    "However, this approach ignores the fact that there are many parameter values that *could* have generated the same data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "Instead, what we'd really like to know is the full set of possible parameters given the data:\n",
    "\n",
    "$$P(\\theta \\mid D)$$\n",
    "\n",
    "This should look familiar and a probability reminder should give a hint for how to calculate it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability reminder\n",
    "\n",
    "### A and B\n",
    "$$P(A \\cap B) = P(A \\mid B) P(B) = P(B \\mid A) P(A)$$\n",
    "\n",
    "### A given B \n",
    "$$P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B \\mid A) P(A)}{P(B)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Rule\n",
    "\n",
    "$$P(\\theta \\mid D) = \\frac{P(\\theta \\cap D)}{P(D)} = \\frac{P(D \\mid \\theta) P(\\theta)}{P(D)} \\propto P(D \\mid \\theta) P(\\theta)$$\n",
    "\n",
    "- $P(\\theta \\mid D)$ is the posterior probability\n",
    "- $P(D \\mid \\theta)$ is the likelihood\n",
    "- $P(\\theta)$ is the prior probability\n",
    "- $P(D)$ is the marginal likelihood (*does not depend on model or params*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's a prior?\n",
    "\n",
    "A prior probability represents the initial belief in the potential values of some quantity before any new evidence is taken into account.\n",
    "\n",
    "The notion of a prior is one of the key differences between Bayesian and Frequentist approaches. Bayesians believe that we should take such prior knowledge into account when making decisions and that this prior knowledge can be updated with each new bit of evidence:\n",
    "\n",
    "\"Today's posterior is tomorrow's prior\"\n",
    "\n",
    "That said, priors are also a major critique of Bayesian approaches because they can have a massive effect on the posterior (i.e., the conclusions you draw)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "Determining $P(\\theta \\mid D)$ can be difficult for a number of reasons:\n",
    "\n",
    "- The likelihood $P(D \\mid \\theta)$ is often intractable, requiring simulation\n",
    "- Can be unfeasible/impossible to determine the marginal likelihood ($P(D)$)\n",
    "\n",
    "The standard approach is to use Markov chain Monte Carlo (MCMC) to estimate the posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCMC - Metropolis Hastings algorithm\n",
    "\n",
    "The basic idea is that if you take repeated samples of the space of a known function that is *proportional* to the posterior, then you will eventually gain a reasonable estimate of that probability distribution.\n",
    "\n",
    "The basic steps are as follows:\n",
    "\n",
    "0. Initialize a starting parameter set with a non-zero likelihood\n",
    "1. Generate a parameter proposal\n",
    "2. Calculate likelihood for that proposal\n",
    "3. Compare with the previous parameter and decide whether to accept it\n",
    "4. Repeat steps 1--3 until you have a stable estimate of the posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 0. Initializing the chain\n",
    "\n",
    "Before we can start exploring the posterior we have to get a starting set of parameter values ($\\theta_0$) with a non-zero likelihood. \n",
    "\n",
    "The most common way of doing this is to sample randomly from the priors for each parameter and evaluate the model likelihood, repeating until you find parameter set that has a non-zero likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Proposal generation\n",
    "\n",
    "The key to generating a Markov chain is that each proposal must depend *only* on the current state. \n",
    "\n",
    "Furthermore, in order to properly sample the entire space of the posterior function, these proposals must be *symmetric*. This means that the probability of generating a specific parameter set based on the current state must equal the probability of generating the current parameters given the proposal. \n",
    "\n",
    "This is also referred to as a symmetric transition probability.\n",
    "\n",
    "There are many ways to generate symmetric proposals, but the easiest (and least efficient) is to draw from a normal distribution centered on each current parameter value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Likelihood calculation\n",
    "\n",
    "Once you have a proposed parameter set, you must calculate the likelihood of observing the data given those parameter values and your model. \n",
    "\n",
    "This is identical to what we have done before when calculating the maximum likelihood via gradient descent. \n",
    "\n",
    "Your model can be any function, from a probability distribution to a large-scale cognitive model, so long as you can return a log likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Acceptance ratio\n",
    "\n",
    "Once you've evaluated the likelihood of observing the data given your parameters, you need to decide whether this parameter proposal is worth keeping. Here we calculate a probability of accepting the proposal based on the ratio of posterior probability values:\n",
    "\n",
    "$$P(\\text{accept}) = \\frac{P(D \\mid x') P(x')}{P(D \\mid x_i) P(x_i)},$$\n",
    "\n",
    "where $x'$ is the parameter proposal and $x_i$ is the current parameter at iteration $i$. Note that we can ignore the denominator of the posterior probability function, $P(D)$ because it cancels out in the ratio.\n",
    "\n",
    "Then you simply draw a uniform random number between $[0, 1)$, and if that value is less than the acceptance probability you accept the proposal and replace the current value, otherwise you copy the current state of the parameters to the new state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *ONLY* if on Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the dists.py and data files\n",
    "!wget https://raw.githubusercontent.com/compmem/QuantCog/2020_Spring/notebooks/dists.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "from scipy import stats\n",
    "\n",
    "import dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# function for generating proposals\n",
    "def gen_proposal(x, std=0.1):\n",
    "    # use normal distribution centered at current value\n",
    "    # to generate new value\n",
    "    # loops over each parameter in the set\n",
    "    x_new = [dists.normal(mean=x[i], std=std).rvs()\n",
    "             for i in range(len(x))]\n",
    "    \n",
    "    # convert from list to array and return\n",
    "    return np.array(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# explore the proposal generation random walk\n",
    "# start at 0,0\n",
    "props = [np.array([0., 0.])]\n",
    "\n",
    "# generate 50 sequential proposals\n",
    "for i in range(500):\n",
    "    # call proposal gen with the last proposal\n",
    "    props.append(gen_proposal(props[-1], std=.01))\n",
    "\n",
    "# convert list of arrays into an array\n",
    "props = np.array(props)\n",
    "\n",
    "# plot the random walk\n",
    "plt.plot(props[:,0], props[:,1], 'o-');\n",
    "\n",
    "# what happens when you adjust the std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Provide way to evaluate the prior\n",
    "def eval_prior(x, priors):\n",
    "    # make sure we can loop through it\n",
    "    x = np.atleast_1d(x)\n",
    "    \n",
    "    # loop over each param and associated prior, calculating the PDF\n",
    "    return np.array([np.log(priors[i].pdf(x[i])) \n",
    "                     for i in range(len(x))]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [dists.normal(0, 0.5),\n",
    "          dists.uniform(-5, 5)]\n",
    "eval_prior([0, -2], priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MCMC!!!\n",
    "def MCMC(like_fun, x0=None, args=None, priors=None, niter=10000, std=0.1):  \n",
    "    # process the args\n",
    "    if args is None:\n",
    "        args = ()\n",
    "        \n",
    "    # 0. get starting point\n",
    "    if x0 is None:\n",
    "        # draw from the priors\n",
    "        x0 = [priors[i].rvs() for i in range(len(priors))]\n",
    "        ll0 = like_fun(x0, *args)\n",
    "        while np.isnan(ll0) or np.isinf(ll0):\n",
    "            x0 = [priors[i].rvs() for i in len(priors)]\n",
    "            ll0 = like_fun(x0, *args)\n",
    "    else:\n",
    "        # eval the starting point\n",
    "        ll0 = like_fun(x0, *args)\n",
    "        if np.isnan(ll0) or np.isinf(ll0):\n",
    "            raise ValueError('The starting point has a zero likelihood.')\n",
    "            \n",
    "    print('Starting point:', x0)\n",
    "    print('Log Like:', ll0)\n",
    "\n",
    "    # initialize the chain and associated likelihood\n",
    "    chain = [x0]\n",
    "    log_like = [ll0]\n",
    "\n",
    "    # sample from the posterior\n",
    "    for i in range(niter):\n",
    "        # 1. generate a new proposal from the last accepted params\n",
    "        x_new = gen_proposal(chain[-1], std=std)\n",
    "\n",
    "        # 2. evaluate that new proposal\n",
    "        ll_new = like_fun(x_new, *args)\n",
    "\n",
    "        # 3. calculate the acceptance ratio\n",
    "        accept_ratio = np.exp(ll_new - log_like[-1])\n",
    "\n",
    "        # see if we should use priors\n",
    "        if priors is not None:\n",
    "             accept_ratio *= np.exp(eval_prior(x_new, priors) - \n",
    "                                    eval_prior(chain[-1], priors))\n",
    "\n",
    "        # decide whether to keep the proposal, or copy the previous\n",
    "        if (accept_ratio > 1.0) or (np.random.rand() < accept_ratio):\n",
    "            # accept it\n",
    "            chain.append(x_new)\n",
    "            log_like.append(ll_new)\n",
    "        else:\n",
    "            # repeat the previous\n",
    "            chain.append(chain[-1])\n",
    "            log_like.append(log_like[-1])\n",
    "\n",
    "    # convert the chain and log_likes to arrays\n",
    "    chain = np.array(chain)\n",
    "    log_like = np.array(log_like)\n",
    "    \n",
    "    return chain, log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validate MCMC on known function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# likelihood function\n",
    "def like_fun(x, *args):\n",
    "    # evaluate the model given the params\n",
    "    # in this case the params are the points where we're evaluating the model\n",
    "    return np.log(dists.normal(-.5, 0.5).pdf(x))\n",
    "\n",
    "# define some priors (or not)\n",
    "#priors = [dists.normal(1.0, .5)]\n",
    "priors = None\n",
    "\n",
    "chain, log_like = MCMC(like_fun, x0=[0.0], priors=priors, niter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot the chain through time\n",
    "plt.plot(chain[:,0])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot the estimated and true posterior\n",
    "burnin = 100\n",
    "x = np.linspace(-4,4,100)\n",
    "plt.hist(chain[burnin:], bins='auto', density=True, alpha=.5);\n",
    "plt.plot(x, np.exp(like_fun(x)), '-', lw=3)\n",
    "\n",
    "#plt.plot(x, priors[0].pdf(x), '-', lw=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explore the effects of priors\n",
    "\n",
    "Go back up and try various priors and see how it affects the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Estimation Supersedes the t-Test (BEST)\n",
    "\n",
    "Why be just good when you could be the BEST?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generate some data that may or may not be significantly different from zero\n",
    "A = dists.normal(mean=0.3, std=0.5).rvs(10)\n",
    "\n",
    "# plot it\n",
    "plt.hist(A, bins='auto', density=True);\n",
    "\n",
    "# do a quick t-test\n",
    "stats.ttest_1samp(A, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up priors for mean, std, and df of Student's T\n",
    "priors = [dists.normal(A.mean(), A.std()*2.0),\n",
    "          dists.uniform(0.01, 10.),\n",
    "          #dists.exp(1/29.)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot those priors\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, priors[0].pdf(x), lw=3)\n",
    "plt.title('Mean Prior')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "x = np.linspace(-5, 15, 100)\n",
    "plt.plot(x, priors[1].pdf(x), lw=3)\n",
    "plt.title('Std Prior')\n",
    "\n",
    "#plt.subplot(1, 3, 3)\n",
    "#x = np.linspace(0, 50, 100)\n",
    "#plt.plot(x, priors[2].pdf(x), lw=3)\n",
    "#plt.title('Df Prior')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def ttest_like_fun(x, *args):\n",
    "    # process the args\n",
    "    obs = args[0]\n",
    "    \n",
    "    # evaluate the model given the params\n",
    "    return np.log(dists.students_t(mean=x[0], \n",
    "                                   std=x[1], \n",
    "                                   df=len(obs)-1.).pdf(obs)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# run MCMC\n",
    "chain, log_like = MCMC(ttest_like_fun, x0=None, args=(A,), \n",
    "                       priors=priors, niter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot the chain through time\n",
    "plt.plot(chain[:,0])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(log_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 1500\n",
    "plt.hist(chain[1500:,0], density=True, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There's got to be a better way...\n",
    "\n",
    "Next class we'll explore how we can use existing libraries to do the hard work for us..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
