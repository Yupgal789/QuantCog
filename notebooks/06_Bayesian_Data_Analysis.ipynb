{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 6: Bayesian Data Analysis\n",
    "\n",
    "## Intro to Quantified Cognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lesson plan\n",
    "\n",
    "- Deep dive into various Bayesian models of one dataset\n",
    "- Explore other datasets\n",
    "- Real-world data analysis in teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "from scipy import stats\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hierarchical Regression\n",
    "\n",
    "What should we do when we have multiple groups/subjects?\n",
    "\n",
    "Ideally we should share information across groups to inform the models fit to the individuals.\n",
    "\n",
    "This is called multi-level or hierarchical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flanker dataset\n",
    "\n",
    "We will explore a number of ways to analyze a flanker task dataset. \n",
    "\n",
    "You can then use these as a guide when you analyze some of the other datasets we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "dat = pd.read_csv('data/flanker_dat.csv')\n",
    "\n",
    "# remove nans\n",
    "dat = dat[~np.isnan(dat['rt'])]\n",
    "\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get various ways to index the data\n",
    "# see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = preprocessing.LabelEncoder()\n",
    "subj_idx = le.fit_transform(dat['subj'])\n",
    "cond_idx = le.fit_transform(dat['condition'])\n",
    "n_subj = len(dat.subj.unique())\n",
    "n_cond = len(dat.condition.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually best to look at log rt\n",
    "dat['log_rt'] = np.log(dat['rt'])\n",
    "\n",
    "# also add in some info about where the stimuli were presented\n",
    "dat['abs_x'] = np.abs(dat.loc_x)\n",
    "dat['abs_y'] = np.abs(dat.loc_y)\n",
    "dat['angle_rad'] = np.arctan2(dat.loc_y, dat.loc_x)\n",
    "dat['angle_deg'] = dat['angle_rad']*180/np.pi\n",
    "dat.groupby(['angle_deg'])['log_rt'].mean().plot()\n",
    "\n",
    "\n",
    "# show the columns we have to work with\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how distribution of log_rts is mostly normal\n",
    "plt.hist(dat['log_rt'].values, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore effects on reaction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show overall mean log_rt for each condition\n",
    "dat.groupby(['condition'])['log_rt'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overall mean:', dat.log_rt.mean())\n",
    "print('Overall std:', dat.log_rt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine gamma prior on the half cauchy scale\n",
    "x = np.linspace(1, 50, 100)\n",
    "plt.plot(x, np.exp(pm.Gamma.dist(.5, .5).logp(x).eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical version of *t*-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hierarchical model\n",
    "with pm.Model() as hierarchical_model:\n",
    "    \n",
    "    # hyperprior for mu\n",
    "    mu_mu = pm.Normal('mu_mu', \n",
    "                        mu=dat.log_rt.mean(), \n",
    "                        sd=dat.log_rt.std()*2,\n",
    "                        shape=n_cond)\n",
    "    sigma_mu = pm.HalfCauchy('sigma_mu', 10, shape=n_cond)\n",
    "    \n",
    "    # prior on mu\n",
    "    mu = pm.Normal('mu', mu_mu, sigma_mu, \n",
    "                   shape=(n_subj, n_cond))\n",
    "    \n",
    "    # hyperprior for sd (Gelman suggests gamma prior)\n",
    "    sd_scale = pm.Gamma('sd_scale', .5, .5,\n",
    "                        shape=n_cond)\n",
    "    \n",
    "    # prior on sd\n",
    "    sd = pm.HalfCauchy('sd', sd_scale, \n",
    "                       shape=(n_subj, n_cond))\n",
    "    \n",
    "    # prior on df (fixed for all params)\n",
    "    nu = pm.Exponential('df_minus_one', 1/29.) + 1.\n",
    "    \n",
    "    # likelihood\n",
    "    log_rt_like = pm.StudentT('log_rt_like', \n",
    "                              mu=mu[subj_idx, cond_idx], \n",
    "                              sd=sd[subj_idx, cond_idx],\n",
    "                              nu=nu,\n",
    "                              observed=dat.log_rt)\n",
    "    \n",
    "    # save out some comparisons of interest\n",
    "    mudiff01 = pm.Deterministic('mu_diff_01', mu_mu[1]-mu_mu[0])\n",
    "    mudiff02 = pm.Deterministic('mu_diff_02', mu_mu[2]-mu_mu[0])\n",
    "    mudiff12 = pm.Deterministic('mu_diff_12', mu_mu[2]-mu_mu[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    trace = pm.sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our traces\n",
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show comparisons of interest\n",
    "pm.plot_posterior(trace, varnames=['mu_diff_01', 'mu_diff_12', 'mu_diff_02'], \n",
    "                  ref_val=0.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical version of linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ned to make a numerical condition variable\n",
    "dat['num_cond'] = 0\n",
    "dat.loc[dat['condition']=='=', 'num_cond'] = 1\n",
    "dat.loc[dat['condition']=='~', 'num_cond'] = 2\n",
    "dat.num_cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hierarchical model\n",
    "with pm.Model() as hierarchical_linear_model:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_inter = pm.Normal('mu_inter', mu=dat.log_rt.mean(), sd=dat.log_rt.std()*10)\n",
    "    sigma_inter = pm.HalfCauchy('sigma_inter', 10)\n",
    "    \n",
    "    mu_slope = pm.Normal('mu_slope', mu=0., sd=dat.log_rt.std()*10)\n",
    "    sigma_slope = pm.HalfCauchy('sigma_slope', 10)\n",
    "\n",
    "    # Intercept for each subj, distributed around group mean\n",
    "    intercept = pm.Normal('intercept', mu=mu_inter, sd=sigma_inter, shape=n_subj)\n",
    "    \n",
    "    # slope for each subj, distributed around group mean\n",
    "    slope = pm.Normal('slope', mu=mu_slope, sd=sigma_slope, shape=n_subj)\n",
    "\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "    \n",
    "    # define the means predicted from a linear function\n",
    "    log_rt_est = intercept[subj_idx] + slope[subj_idx] * dat.num_cond.values\n",
    "\n",
    "    # Data likelihood (could also replace with Student's t)\n",
    "    log_rt_like = pm.Normal('log_rt_like', mu=log_rt_est, sd=eps, observed=dat.log_rt)\n",
    "    \n",
    "    # Data with Student's t likelihood\n",
    "    # prior on df (fixed for all params)\n",
    "    #nu = pm.Exponential('df_minus_one', 1/29.) + 1.\n",
    "    #log_rt_like = pm.StudentT('log_rt_like', mu=log_rt_est, sd=eps, nu=nu, observed=dat.log_rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_linear_model:\n",
    "    trace = pm.sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['mu_slope_cond', 'mu_slope_y'], ref_val=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_linear_model:\n",
    "    print(pm.waic(trace))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More-complicated linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hierarchical model\n",
    "with pm.Model() as hierarchical_linear_model:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_inter = pm.Normal('mu_inter', mu=dat.log_rt.mean(), sd=dat.log_rt.std()*10)\n",
    "    sigma_inter = pm.HalfCauchy('sigma_inter', 10)\n",
    "    \n",
    "    mu_slope_cond = pm.Normal('mu_slope_cond', mu=0., sd=dat.log_rt.std()*10)\n",
    "    sigma_slope_cond = pm.HalfCauchy('sigma_slope_cond', 10)\n",
    "    #mu_slope_y = pm.Normal('mu_slope_y', mu=0., sd=dat.log_rt.std()*10)\n",
    "    #sigma_slope_y = pm.HalfCauchy('sigma_slope_y', 10)\n",
    "\n",
    "    # Intercept for each subj, distributed around group mean\n",
    "    intercept = pm.Normal('intercept', mu=mu_inter, sd=sigma_inter, shape=n_subj)\n",
    "    \n",
    "    # slope for each subj, distributed around group mean\n",
    "    slope_cond = pm.Normal('slope_cond', mu=mu_slope_cond, sd=sigma_slope_cond, shape=n_subj)\n",
    "    #slope_y = pm.Normal('slope_y', mu=mu_slope_y, sd=sigma_slope_y, shape=n_subj)\n",
    "\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 10)\n",
    "    \n",
    "    # define the means predicted from a linear function\n",
    "    log_rt_est = (intercept[subj_idx] + #slope_y[subj_idx] * dat.abs_y.values + \n",
    "                  slope_cond[subj_idx] * dat.num_cond.values)\n",
    "\n",
    "    # Data likelihood (could also replace with Student's t)\n",
    "    log_rt_like = pm.Normal('log_rt_like', mu=log_rt_est, sd=eps, observed=dat.log_rt)\n",
    "    \n",
    "    # Data with Student's t likelihood\n",
    "    # prior on df (fixed for all params)\n",
    "    #nu = pm.Exponential('df_minus_one', 1/29.) + 1.\n",
    "    #log_rt_like = pm.StudentT('log_rt_like', mu=log_rt_est, sd=eps, nu=nu, observed=dat.log_rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_linear_model:\n",
    "    trace = pm.sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, varnames=['mu_slope_cond', 'mu_slope_y'], ref_val=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_linear_model:\n",
    "    print(pm.waic(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate percent correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about mean performance\n",
    "dat.groupby(['condition'])['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.groupby(['condition'])['correct'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "#y = np.exp(pm.Beta.dist(mu=.75, sd=.1).logp(x).eval())\n",
    "y = np.exp(pm.HalfCauchy.dist(.1).logp(x).eval())\n",
    "#y = np.sqrt(x*(1-x))\n",
    "#y = np.exp(pm.TruncatedNormal.dist(mu=dat.correct.mean(), \n",
    "#                              sd=dat.correct.std()*2, \n",
    "#                              lower=0.0, upper=1.0).logp(x).eval())\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hierarchical model\n",
    "with pm.Model() as perf_model:\n",
    "    \n",
    "    # prior on mu (one for each cond)\n",
    "    mu = pm.TruncatedNormal('mu',\n",
    "                            mu=dat.correct.mean(), \n",
    "                            sd=dat.correct.std()*2, \n",
    "                            lower=0.0, upper=1.0,\n",
    "                            shape=n_cond)\n",
    "    \n",
    "    # prior on sd (one for each cond)\n",
    "    sd = pm.HalfCauchy('sd', 0.1, shape=n_cond)\n",
    "    \n",
    "    # likelihood\n",
    "    prob = pm.Beta('beta', \n",
    "                   mu=mu,\n",
    "                   sd=sd,\n",
    "                   shape=(n_subj, n_cond))\n",
    "    \n",
    "    perf = pm.Binomial('perf', \n",
    "                       n=1,\n",
    "                       p=prob[subj_idx, cond_idx],\n",
    "                       observed=dat.correct)\n",
    "    \n",
    "    # save out some comparisons of interest\n",
    "    mudiff01 = pm.Deterministic('mu_diff_01', mu[1]-mu[0])\n",
    "    mudiff02 = pm.Deterministic('mu_diff_02', mu[2]-mu[0])\n",
    "    mudiff12 = pm.Deterministic('mu_diff_12', mu[2]-mu[1])\n",
    "    \n",
    "    sddiff01 = pm.Deterministic('sd_diff_01', sd[1]-sd[0])\n",
    "    sddiff02 = pm.Deterministic('sd_diff_02', sd[2]-sd[0])\n",
    "    sddiff12 = pm.Deterministic('sd_diff_12', sd[2]-sd[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with perf_model:\n",
    "    trace = pm.sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our traces\n",
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show comparisons of interest\n",
    "pm.plot_posterior(trace, varnames=['mu_diff_01', 'mu_diff_12', 'mu_diff_02', \n",
    "                                   'sd_diff_01', 'sd_diff_12', 'sd_diff_02'], \n",
    "                  ref_val=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = trace.get_values('beta')\n",
    "plt.hist(probs[:,0,0]-probs[:,0,1], bins='auto', alpha=.3);\n",
    "plt.hist(probs[:,0,1]-probs[:,0,2], bins='auto', alpha=.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdiff = [((probs[:,i,0] - probs[:,i,1])>0.0).sum()/len(probs) \n",
    "         for i in range(probs.shape[1])]\n",
    "plt.hist(pdiff, bins='auto');"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
